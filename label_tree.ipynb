{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPox/BCQCBLCk9ZB5M0S3js",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omar-omar-om/gradProject-notebooks/blob/main/label_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "MR16IpjtneG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiSIdTdNk2RH",
        "outputId": "aac574ee-1be4-42e1-db10-9b644f41e814"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4EKv5H8lByb",
        "outputId": "47cbc96a-34f8-44b5-d247-6de1cb4f8e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqf8xMyYnFFk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Paths & Load Data\n"
      ],
      "metadata": {
        "id": "O-8cg-LMntE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "base_path = \"/content/drive/My Drive/label-encoding/\"\n",
        "model_save_path = os.path.join(base_path, \"best_model/\")\n",
        "\n",
        "# Ensure model directory exists\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "train = pd.read_csv(os.path.join(base_path, \"train_label.csv\"))\n",
        "val = pd.read_csv(os.path.join(base_path, \"val_label.csv\"))\n",
        "test = pd.read_csv(os.path.join(base_path, \"test_label.csv\"))\n",
        "\n",
        "# Identify features and target\n",
        "target = \"HasDetections\"\n",
        "X_train, y_train = train.drop(columns=[target]), train[target]\n",
        "X_val, y_val = val.drop(columns=[target]), val[target]\n",
        "X_test, y_test = test.drop(columns=[target]), test[target]\n",
        "\n",
        "print(f\" Data loaded. Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loNA1Zn6nwOn",
        "outputId": "3f803d6d-784e-4e43-e676-ddac50d449d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Data loaded. Train shape: (2062484, 61), Validation shape: (257810, 61), Test shape: (257811, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Models & Hyperparameters for Grid Search\n"
      ],
      "metadata": {
        "id": "bLByp7Y9ttD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and their respective expanded hyperparameter grids\n",
        "models = {\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 300],\n",
        "            \"max_depth\": [3, 9],\n",
        "            \"learning_rate\": [0.01, 0.1],\n",
        "            \"subsample\": [0.8, 1.0],\n",
        "            \"colsample_bytree\": [0.8, 1.0]\n",
        "        }\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"model\": LGBMClassifier(),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 300],\n",
        "            \"max_depth\": [-1, 6],\n",
        "            \"learning_rate\": [0.01, 0.1],\n",
        "            \"num_leaves\": [31, 50]\n",
        "            }\n",
        "    },\n",
        "    \"DecisionTree\": {\n",
        "        \"model\": DecisionTreeClassifier(),\n",
        "        \"params\": {\n",
        "            \"max_depth\": [None, 6, 12, 20],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "            \"min_samples_split\": [2, 5, 10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Models and expanded hyperparameter grids defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdokV6D3tg22",
        "outputId": "cf948a68-9d3e-4898-c008-3131b5123999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and expanded hyperparameter grids defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Grid Search & Select the Best Model\n",
        "\n"
      ],
      "metadata": {
        "id": "6IQMSjT7twmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tracking variables\n",
        "best_model = None\n",
        "best_auc = 0\n",
        "best_model_name = None\n",
        "timing_results = []\n",
        "\n",
        "for model_name, config in models.items():\n",
        "    print(f\" Running Grid Search for {model_name}...\")\n",
        "\n",
        "    # Track Grid Search time\n",
        "    start_grid_search = time.time()\n",
        "\n",
        "    grid_search = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    end_grid_search = time.time()\n",
        "    grid_search_time = end_grid_search - start_grid_search  # Total Grid Search time\n",
        "\n",
        "    # Get the best estimator\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Track final model training time (with best hyperparameters)\n",
        "    start_train = time.time()\n",
        "    best_estimator.fit(X_train, y_train)  # Retraining the best model\n",
        "    end_train = time.time()\n",
        "    training_time = end_train - start_train  # Training time for best model only\n",
        "\n",
        "    # Track evaluation time\n",
        "    start_eval = time.time()\n",
        "    y_pred = best_estimator.predict(X_val)\n",
        "    y_prob = best_estimator.predict_proba(X_val)[:, 1]  # Probability scores for AUC\n",
        "    end_eval = time.time()\n",
        "    evaluation_time = end_eval - start_eval  # Total evaluation time\n",
        "\n",
        "    # Compute AUC Score\n",
        "    val_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "    print(f\" {model_name} Best AUC on Validation Set: {val_auc:.4f}\")\n",
        "\n",
        "    # Store timing results\n",
        "    timing_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Grid Search Time (s)\": round(grid_search_time, 2),\n",
        "        \"Final Training Time (s)\": round(training_time, 2),\n",
        "        \"Evaluation Time (s)\": round(evaluation_time, 2),\n",
        "        \"AUC Score\": round(val_auc, 4)\n",
        "    })\n",
        "\n",
        "    # Check if this is the best model\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc\n",
        "        best_model = best_estimator\n",
        "        best_model_name = model_name\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "timing_df = pd.DataFrame(timing_results)\n",
        "print(\"\\n Training & Evaluation Time Results:\")\n",
        "print(timing_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name} with AUC: {best_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vk62OTxtzcB",
        "outputId": "999dc5ea-cab0-4586-f4d3-3ffa29d80487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running Grid Search for XGBoost...\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:46:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:48:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " XGBoost Best AUC on Validation Set: 0.7318\n",
            " Running Grid Search for LightGBM...\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "[LightGBM] [Info] Number of positive: 1034588, number of negative: 1027896\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.629898 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4965\n",
            "[LightGBM] [Info] Number of data points in the train set: 2062484, number of used features: 61\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501622 -> initscore=0.006489\n",
            "[LightGBM] [Info] Start training from score 0.006489\n",
            "[LightGBM] [Info] Number of positive: 1034588, number of negative: 1027896\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.788852 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4965\n",
            "[LightGBM] [Info] Number of data points in the train set: 2062484, number of used features: 61\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501622 -> initscore=0.006489\n",
            "[LightGBM] [Info] Start training from score 0.006489\n",
            " LightGBM Best AUC on Validation Set: 0.7282\n",
            " Running Grid Search for DecisionTree...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            " DecisionTree Best AUC on Validation Set: 0.6971\n",
            "\n",
            " Training & Evaluation Time Results:\n",
            "       Model  Grid Search Time (s)  Final Training Time (s)  Evaluation Time (s)  AUC Score\n",
            "     XGBoost               5607.62                   134.34                 5.19     0.7318\n",
            "    LightGBM               3287.32                   147.91                12.07     0.7282\n",
            "DecisionTree               2434.74                    46.44                 0.20     0.6971\n",
            "\n",
            "Best Model: XGBoost with AUC: 0.7318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Best Model as a Pickle File\n",
        "\n"
      ],
      "metadata": {
        "id": "lYbY_x-nuXJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model save path\n",
        "best_model_path = os.path.join(model_save_path, f\"best_{best_model_name}.pkl\")\n",
        "\n",
        "# Save the model\n",
        "with open(best_model_path, \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\" Best model ({best_model_name}) saved to {best_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANiBoy1-uZ42",
        "outputId": "8eaf5874-f855-416e-93c5-b023f7c5e28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best model (XGBoost) saved to /content/drive/My Drive/label-encoding/best_model/best_XGBoost.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Evaluate the Best Model (All Metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "SAOR2YLhue8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the best model\n",
        "with open(best_model_path, \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = loaded_model.predict(X_test)\n",
        "y_test_prob = loaded_model.predict_proba(X_test)[:, 1]  # Probability scores for AUC\n",
        "\n",
        "# Calculate metrics\n",
        "test_auc = roc_auc_score(y_test, y_test_prob)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "# Print all metrics\n",
        "print(f\"\\n Best Model: {best_model_name} Performance on Test Set\")\n",
        "print(f\"AUC Score: {test_auc:.4f}\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "print(\"Model evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQhdqCYluhF2",
        "outputId": "e10b3281-2577-4a82-b5f2-e796bb910e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Model: XGBoost Performance on Test Set\n",
            "AUC Score: 0.7312\n",
            "Accuracy: 0.6652\n",
            "Precision: 0.6676\n",
            "Recall: 0.6624\n",
            "F1 Score: 0.6650\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.67      0.67    128487\n",
            "           1       0.67      0.66      0.66    129324\n",
            "\n",
            "    accuracy                           0.67    257811\n",
            "   macro avg       0.67      0.67      0.67    257811\n",
            "weighted avg       0.67      0.67      0.67    257811\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    }
  ]
}