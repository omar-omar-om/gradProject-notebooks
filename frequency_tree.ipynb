{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR8nhhlzipI8gR1c+X6Jcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omar-omar-om/gradProject-notebooks/blob/main/frequency_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Libraries"
      ],
      "metadata": {
        "id": "MR16IpjtneG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqf8xMyYnFFk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Paths & Load Data\n"
      ],
      "metadata": {
        "id": "O-8cg-LMntE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "base_path = \"/content/drive/My Drive/frequency-encoding/\"\n",
        "model_save_path = os.path.join(base_path, \"best_model/\")\n",
        "\n",
        "# Ensure model directory exists\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "# Load dataset\n",
        "train = pd.read_csv(os.path.join(base_path, \"train_frequency.csv\"))\n",
        "val = pd.read_csv(os.path.join(base_path, \"val_frequency.csv\"))\n",
        "test = pd.read_csv(os.path.join(base_path, \"test_frequency.csv\"))\n",
        "\n",
        "# Identify features and target\n",
        "target = \"HasDetections\"\n",
        "X_train, y_train = train.drop(columns=[target]), train[target]\n",
        "X_val, y_val = val.drop(columns=[target]), val[target]\n",
        "X_test, y_test = test.drop(columns=[target]), test[target]\n",
        "\n",
        "print(f\" Data loaded. Train shape: {X_train.shape}, Validation shape: {X_val.shape}, Test shape: {X_test.shape}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loNA1Zn6nwOn",
        "outputId": "58281d1a-0562-4b9f-d58b-496e3256578a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Data loaded. Train shape: (2062484, 61), Validation shape: (257810, 61), Test shape: (257811, 61)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Models & Hyperparameters for Grid Search\n"
      ],
      "metadata": {
        "id": "bLByp7Y9ttD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define models and their respective expanded hyperparameter grids\n",
        "models = {\n",
        "    \"XGBoost\": {\n",
        "        \"model\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 300],\n",
        "            \"max_depth\": [3, 9],\n",
        "            \"learning_rate\": [0.01, 0.1],\n",
        "            \"subsample\": [0.8, 1.0],\n",
        "            \"colsample_bytree\": [0.8, 1.0]\n",
        "        }\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"model\": LGBMClassifier(),\n",
        "        \"params\": {\n",
        "            \"n_estimators\": [100, 300],\n",
        "            \"max_depth\": [-1, 6],\n",
        "            \"learning_rate\": [0.01, 0.1],\n",
        "            \"num_leaves\": [31, 50]\n",
        "            }\n",
        "    },\n",
        "    \"DecisionTree\": {\n",
        "        \"model\": DecisionTreeClassifier(),\n",
        "        \"params\": {\n",
        "            \"max_depth\": [None, 6, 12, 20],\n",
        "            \"criterion\": [\"gini\", \"entropy\"],\n",
        "            \"min_samples_split\": [2, 5, 10]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Models and expanded hyperparameter grids defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdokV6D3tg22",
        "outputId": "7af290a7-700a-4e6b-ec1d-9faf13b6d87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models and expanded hyperparameter grids defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Grid Search & Select the Best Model\n",
        "\n"
      ],
      "metadata": {
        "id": "6IQMSjT7twmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tracking variables\n",
        "best_model = None\n",
        "best_auc = 0\n",
        "best_model_name = None\n",
        "timing_results = []\n",
        "\n",
        "for model_name, config in models.items():\n",
        "    print(f\" Running Grid Search for {model_name}...\")\n",
        "\n",
        "    # Track Grid Search time\n",
        "    start_grid_search = time.time()\n",
        "\n",
        "    grid_search = GridSearchCV(config[\"model\"], config[\"params\"], cv=3, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    end_grid_search = time.time()\n",
        "    grid_search_time = end_grid_search - start_grid_search  # Total Grid Search time\n",
        "\n",
        "    # Get the best estimator\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Track final model training time (with best hyperparameters)\n",
        "    start_train = time.time()\n",
        "    best_estimator.fit(X_train, y_train)  # Retraining the best model\n",
        "    end_train = time.time()\n",
        "    training_time = end_train - start_train  # Training time for best model only\n",
        "\n",
        "    # Track evaluation time\n",
        "    start_eval = time.time()\n",
        "    y_pred = best_estimator.predict(X_val)\n",
        "    y_prob = best_estimator.predict_proba(X_val)[:, 1]  # Probability scores for AUC\n",
        "    end_eval = time.time()\n",
        "    evaluation_time = end_eval - start_eval  # Total evaluation time\n",
        "\n",
        "    # Compute AUC Score\n",
        "    val_auc = roc_auc_score(y_val, y_prob)\n",
        "\n",
        "    print(f\" {model_name} Best AUC on Validation Set: {val_auc:.4f}\")\n",
        "\n",
        "    # Store timing results\n",
        "    timing_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Grid Search Time (s)\": round(grid_search_time, 2),\n",
        "        \"Final Training Time (s)\": round(training_time, 2),\n",
        "        \"Evaluation Time (s)\": round(evaluation_time, 2),\n",
        "        \"AUC Score\": round(val_auc, 4)\n",
        "    })\n",
        "\n",
        "    # Check if this is the best model\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc\n",
        "        best_model = best_estimator\n",
        "        best_model_name = model_name\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "timing_df = pd.DataFrame(timing_results)\n",
        "print(\"\\n Training & Evaluation Time Results:\")\n",
        "print(timing_df.to_string(index=False))\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name} with AUC: {best_auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vk62OTxtzcB",
        "outputId": "80d5df3d-509b-4010-8944-39fbf6729cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Running Grid Search for XGBoost...\n",
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:41:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:43:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " XGBoost Best AUC on Validation Set: 0.7304\n",
            " Running Grid Search for LightGBM...\n",
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1034588, number of negative: 1027896\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.609664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4958\n",
            "[LightGBM] [Info] Number of data points in the train set: 2062484, number of used features: 61\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501622 -> initscore=0.006489\n",
            "[LightGBM] [Info] Start training from score 0.006489\n",
            "[LightGBM] [Info] Number of positive: 1034588, number of negative: 1027896\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.838718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4958\n",
            "[LightGBM] [Info] Number of data points in the train set: 2062484, number of used features: 61\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501622 -> initscore=0.006489\n",
            "[LightGBM] [Info] Start training from score 0.006489\n",
            " LightGBM Best AUC on Validation Set: 0.7258\n",
            " Running Grid Search for DecisionTree...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            " DecisionTree Best AUC on Validation Set: 0.6947\n",
            "\n",
            " Training & Evaluation Time Results:\n",
            "       Model  Grid Search Time (s)  Final Training Time (s)  Evaluation Time (s)  AUC Score\n",
            "     XGBoost               5884.25                   140.56                 5.30     0.7304\n",
            "    LightGBM               3406.67                   146.05                12.19     0.7258\n",
            "DecisionTree               2417.07                    48.11                 0.21     0.6947\n",
            "\n",
            "Best Model: XGBoost with AUC: 0.7304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Best Model as a Pickle File\n",
        "\n"
      ],
      "metadata": {
        "id": "lYbY_x-nuXJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model save path\n",
        "best_model_path = os.path.join(model_save_path, f\"best_{best_model_name}.pkl\")\n",
        "\n",
        "# Save the model\n",
        "with open(best_model_path, \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n",
        "\n",
        "print(f\" Best model ({best_model_name}) saved to {best_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANiBoy1-uZ42",
        "outputId": "00e9c2df-2a83-40e5-abbe-ae88bcae0b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best model (XGBoost) saved to /content/drive/My Drive/frequency-encoding/best_model/best_XGBoost.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & Evaluate the Best Model (All Metrics)\n",
        "\n"
      ],
      "metadata": {
        "id": "SAOR2YLhue8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the best model\n",
        "with open(best_model_path, \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "# Make predictions\n",
        "y_test_pred = loaded_model.predict(X_test)\n",
        "y_test_prob = loaded_model.predict_proba(X_test)[:, 1]  # Probability scores for AUC\n",
        "\n",
        "# Calculate metrics\n",
        "test_auc = roc_auc_score(y_test, y_test_prob)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_precision = precision_score(y_test, y_test_pred)\n",
        "test_recall = recall_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "# Print all metrics\n",
        "print(f\"\\n Best Model: {best_model_name} Performance on Test Set\")\n",
        "print(f\"AUC Score: {test_auc:.4f}\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "print(\"Model evaluation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQhdqCYluhF2",
        "outputId": "f59a6eaa-32a4-45f1-d1c7-a84cd8134492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best Model: XGBoost Performance on Test Set\n",
            "AUC Score: 0.7295\n",
            "Accuracy: 0.6631\n",
            "Precision: 0.6658\n",
            "Recall: 0.6594\n",
            "F1 Score: 0.6626\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.67      0.66    128487\n",
            "           1       0.67      0.66      0.66    129324\n",
            "\n",
            "    accuracy                           0.66    257811\n",
            "   macro avg       0.66      0.66      0.66    257811\n",
            "weighted avg       0.66      0.66      0.66    257811\n",
            "\n",
            "Model evaluation completed.\n"
          ]
        }
      ]
    }
  ]
}